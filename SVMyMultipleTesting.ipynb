{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo primero que tendermos que realizar es importar la base de datos y verificar si esta tiene huecos dentro de ella."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores faltantes:\n",
      "0\n",
      "Valores originales en el conjunto de datos:\n",
      "(83, 2309)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df=pd.read_csv('Khan.csv')\n",
    "missing_values = df.isnull().sum().sum()\n",
    "print(\"Valores faltantes:\")\n",
    "print(missing_values)\n",
    "print(\"Valores originales en el conjunto de datos:\")\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos observar que la base de datos no cuenta con ningun hueco."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Los 10 genes con la mayor diferencia de medias entre las clases 2 y 4:\n",
      "X187     3.323151\n",
      "X509     2.906537\n",
      "X2046    2.424515\n",
      "X2050    2.401783\n",
      "X129     2.165185\n",
      "X1645    2.065460\n",
      "X1319    2.045941\n",
      "X1955    2.037340\n",
      "X1003    2.011337\n",
      "X246     1.837830\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "# Supongamos que tu DataFrame se llama df y tiene una columna 'y' que indica las clases\n",
    "# y las demás columnas representan los genes.\n",
    "\n",
    "# Filtrar las observaciones de las clases 2 y 4\n",
    "clase_2 = df[df['y'] == 2]\n",
    "clase_4 = df[df['y'] == 4]\n",
    "\n",
    "# Calcular la diferencia de promedios para cada gen\n",
    "# Excluimos la columna 'y' al calcular los promedios\n",
    "diferencias = (clase_2.mean() - clase_4.mean()).drop('y')\n",
    "\n",
    "# Ordenar las diferencias en orden descendente\n",
    "diferencias_ordenadas = diferencias.abs().sort_values(ascending=False)\n",
    "\n",
    "# Imprimir los 10 genes con la mayor diferencia de medias\n",
    "print(\"Los 10 genes con la mayor diferencia de medias entre las clases 2 y 4:\")\n",
    "print(diferencias_ordenadas.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Acabamos de hacer una seleccion de caracteristicas comparando los promedios entre la clase 2 y la clase 4 de nuestro dataframe pero para tener una mejor seleccion compararemos sus p-values y estadisticos t."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Genes con diferencias significativas (Bonferroni):\n",
      "        Gen    t_value       p_value  Bonferroni_corrected  Bonferroni_pval  \\\n",
      "1002  X1003 -12.879590  4.998692e-17                  True     1.153698e-13   \n",
      "186    X187 -12.229464  3.716887e-16                  True     8.578576e-13   \n",
      "2049  X2050 -10.983249  4.084836e-15                  True     9.427801e-12   \n",
      "1954  X1955 -12.579058  5.307128e-15                  True     1.224885e-11   \n",
      "1644  X1645  10.827754  8.262889e-15                  True     1.907075e-11   \n",
      "...     ...        ...           ...                   ...              ...   \n",
      "16      X17   1.720567  9.249593e-02                 False     1.000000e+00   \n",
      "2305  X2306  -1.463430  1.520007e-01                 False     1.000000e+00   \n",
      "2306  X2307  -1.529576  1.322255e-01                 False     1.000000e+00   \n",
      "2307  X2308   0.989658  3.269311e-01                 False     1.000000e+00   \n",
      "0        X1   0.739831  4.627656e-01                 False     1.000000e+00   \n",
      "\n",
      "      Holm_corrected     Holm_pval  BH_corrected       BH_pval  \n",
      "1002            True  1.153698e-13          True  1.153698e-13  \n",
      "186             True  8.574859e-13          True  4.289288e-13  \n",
      "2049            True  9.419631e-12          True  3.062213e-12  \n",
      "1954            True  1.223293e-11          True  3.062213e-12  \n",
      "1644            True  1.903770e-11          True  3.814150e-12  \n",
      "...              ...           ...           ...           ...  \n",
      "16             False  1.000000e+00         False  3.067250e-01  \n",
      "2305           False  1.000000e+00         False  3.997872e-01  \n",
      "2306           False  1.000000e+00         False  3.699110e-01  \n",
      "2307           False  1.000000e+00         False  6.060698e-01  \n",
      "0              False  1.000000e+00         False  7.168208e-01  \n",
      "\n",
      "[2308 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import ttest_ind\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "genes = df.columns.drop('y')  # Excluir la columna de clase\n",
    "t_values = []\n",
    "p_values = []\n",
    "\n",
    "# Calcular el estadístico t y el p-value para cada gen\n",
    "for gen in genes:\n",
    "    t_stat, p_val = ttest_ind(clase_2[gen], clase_4[gen], equal_var=False)  # Prueba t de Student\n",
    "    t_values.append(t_stat)\n",
    "    p_values.append(p_val)\n",
    "\n",
    "# Convertir los resultados a un DataFrame\n",
    "results = pd.DataFrame({\n",
    "    'Gen': genes,\n",
    "    't_value': t_values,\n",
    "    'p_value': p_values\n",
    "})\n",
    "\n",
    "# Aplicar correcciones por múltiples pruebas\n",
    "alpha = 0.05\n",
    "\n",
    "# Bonferroni\n",
    "results['Bonferroni_corrected'], results['Bonferroni_pval'], _, _ = multipletests(results['p_value'], alpha=alpha, method='bonferroni')\n",
    "\n",
    "# Holm\n",
    "results['Holm_corrected'], results['Holm_pval'], _, _ = multipletests(results['p_value'], alpha=alpha, method='holm')\n",
    "\n",
    "# Benjamini-Hochberg\n",
    "results['BH_corrected'], results['BH_pval'], _, _ = multipletests(results['p_value'], alpha=alpha, method='fdr_bh')\n",
    "\n",
    "# Filtrar genes con diferencias significativas para cada método\n",
    "significant_bonferroni = results[results['Bonferroni_corrected']]\n",
    "significant_holm = results[results['Holm_corrected']]\n",
    "significant_bh = results[results['BH_corrected']]\n",
    "\n",
    "sorted_bonferroni = results.sort_values(by='Bonferroni_pval')\n",
    "sorted_holm = results.sort_values(by='Holm_pval')\n",
    "sorted_bh = results.sort_values(by='BH_pval')\n",
    "\n",
    "# Imprimir los resultados\n",
    "print(\"Genes con diferencias significativas (Bonferroni):\")\n",
    "print(sorted_bonferroni)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Genes con diferencias significativas (Holm):\n",
      "        Gen    t_value       p_value  Bonferroni_corrected  Bonferroni_pval  \\\n",
      "1002  X1003 -12.879590  4.998692e-17                  True     1.153698e-13   \n",
      "186    X187 -12.229464  3.716887e-16                  True     8.578576e-13   \n",
      "2049  X2050 -10.983249  4.084836e-15                  True     9.427801e-12   \n",
      "1954  X1955 -12.579058  5.307128e-15                  True     1.224885e-11   \n",
      "1644  X1645  10.827754  8.262889e-15                  True     1.907075e-11   \n",
      "...     ...        ...           ...                   ...              ...   \n",
      "16      X17   1.720567  9.249593e-02                 False     1.000000e+00   \n",
      "2305  X2306  -1.463430  1.520007e-01                 False     1.000000e+00   \n",
      "2306  X2307  -1.529576  1.322255e-01                 False     1.000000e+00   \n",
      "2307  X2308   0.989658  3.269311e-01                 False     1.000000e+00   \n",
      "0        X1   0.739831  4.627656e-01                 False     1.000000e+00   \n",
      "\n",
      "      Holm_corrected     Holm_pval  BH_corrected       BH_pval  \n",
      "1002            True  1.153698e-13          True  1.153698e-13  \n",
      "186             True  8.574859e-13          True  4.289288e-13  \n",
      "2049            True  9.419631e-12          True  3.062213e-12  \n",
      "1954            True  1.223293e-11          True  3.062213e-12  \n",
      "1644            True  1.903770e-11          True  3.814150e-12  \n",
      "...              ...           ...           ...           ...  \n",
      "16             False  1.000000e+00         False  3.067250e-01  \n",
      "2305           False  1.000000e+00         False  3.997872e-01  \n",
      "2306           False  1.000000e+00         False  3.699110e-01  \n",
      "2307           False  1.000000e+00         False  6.060698e-01  \n",
      "0              False  1.000000e+00         False  7.168208e-01  \n",
      "\n",
      "[2308 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "print(\"Genes con diferencias significativas (Holm):\")\n",
    "print(sorted_holm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Genes con diferencias significativas (Benjamini-Hochberg):\n",
      "        Gen    t_value       p_value  Bonferroni_corrected  Bonferroni_pval  \\\n",
      "1002  X1003 -12.879590  4.998692e-17                  True     1.153698e-13   \n",
      "186    X187 -12.229464  3.716887e-16                  True     8.578576e-13   \n",
      "1954  X1955 -12.579058  5.307128e-15                  True     1.224885e-11   \n",
      "2049  X2050 -10.983249  4.084836e-15                  True     9.427801e-12   \n",
      "1644  X1645  10.827754  8.262889e-15                  True     1.907075e-11   \n",
      "...     ...        ...           ...                   ...              ...   \n",
      "1962  X1963  -0.005855  9.953544e-01                 False     1.000000e+00   \n",
      "446    X447  -0.006869  9.945509e-01                 False     1.000000e+00   \n",
      "582    X583  -0.004050  9.967843e-01                 False     1.000000e+00   \n",
      "568    X569   0.003052  9.975796e-01                 False     1.000000e+00   \n",
      "1167  X1168   0.000063  9.999498e-01                 False     1.000000e+00   \n",
      "\n",
      "      Holm_corrected     Holm_pval  BH_corrected       BH_pval  \n",
      "1002            True  1.153698e-13          True  1.153698e-13  \n",
      "186             True  8.574859e-13          True  4.289288e-13  \n",
      "1954            True  1.223293e-11          True  3.062213e-12  \n",
      "2049            True  9.419631e-12          True  3.062213e-12  \n",
      "1644            True  1.903770e-11          True  3.814150e-12  \n",
      "...              ...           ...           ...           ...  \n",
      "1962           False  1.000000e+00         False  9.974695e-01  \n",
      "446            False  1.000000e+00         False  9.974695e-01  \n",
      "582            False  1.000000e+00         False  9.976488e-01  \n",
      "568            False  1.000000e+00         False  9.980120e-01  \n",
      "1167           False  1.000000e+00         False  9.999498e-01  \n",
      "\n",
      "[2308 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "print(\"Genes con diferencias significativas (Benjamini-Hochberg):\")\n",
    "print(sorted_bh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos observar los diferentes p-values de los datos organisados de mas significativo a menos significativo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora realizaremos un analisis de variansa entre los 4 casos posibles de la salida y con eso realisaremos nuestra seleccion final de caracteristicas tomando en cuenta que descartaremos todos los que esten abajo de 0.05 en su p-value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados de ANOVA ordenados por p-value:\n",
      "        Gen     F_stat       p_value\n",
      "1954  X1955  84.364086  1.459035e-24\n",
      "1388  X1389  83.817537  1.772751e-24\n",
      "1002  X1003  77.795622  1.618988e-23\n",
      "2049  X2050  69.230799  4.733702e-22\n",
      "245    X246  68.414042  6.633722e-22\n",
      "...     ...        ...           ...\n",
      "769    X770   0.065309  9.780858e-01\n",
      "1139  X1140   0.054007  9.833477e-01\n",
      "440    X441   0.045939  9.868383e-01\n",
      "937    X938   0.036097  9.907486e-01\n",
      "669    X670   0.010611  9.984902e-01\n",
      "\n",
      "[2308 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import f_oneway\n",
    "\n",
    "# Estratificar los datos por clase\n",
    "clases = [df[df['y'] == clase] for clase in df['y'].unique()]\n",
    "\n",
    "# Excluir la columna 'y' y preparar los datos para ANOVA\n",
    "genes = df.columns.drop('y')\n",
    "anova_results = []\n",
    "\n",
    "for gen in genes:\n",
    "    # Extraer los valores del gen para cada clase\n",
    "    valores_por_clase = [clase[gen].values for clase in clases]\n",
    "    \n",
    "    # Realizar la prueba ANOVA\n",
    "    f_stat, p_val = f_oneway(*valores_por_clase)\n",
    "    anova_results.append({'Gen': gen, 'F_stat': f_stat, 'p_value': p_val})\n",
    "\n",
    "# Convertir los resultados a un DataFrame\n",
    "anova_df = pd.DataFrame(anova_results)\n",
    "\n",
    "# Ordenar por p-value\n",
    "anova_df_sorted = anova_df.sort_values(by='p_value')\n",
    "\n",
    "# Imprimir los resultados ordenados\n",
    "print(\"Resultados de ANOVA ordenados por p-value:\")\n",
    "print(anova_df_sorted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "prosedamos a hacer el seleccion de caractaristicas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Características seleccionadas (p-value <= 0.05):\n",
      "        Gen     F_stat       p_value\n",
      "1954  X1955  84.364086  1.459035e-24\n",
      "1388  X1389  83.817537  1.772751e-24\n",
      "1002  X1003  77.795622  1.618988e-23\n",
      "2049  X2050  69.230799  4.733702e-22\n",
      "245    X246  68.414042  6.633722e-22\n",
      "...     ...        ...           ...\n",
      "1337  X1338   2.734705  4.912248e-02\n",
      "948    X949   2.732694  4.924375e-02\n",
      "658    X659   2.732400  4.926153e-02\n",
      "1033  X1034   2.723469  4.980396e-02\n",
      "1221  X1222   2.720638  4.997709e-02\n",
      "\n",
      "[1303 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Filtrar genes con p-value menor o igual a 0.05\n",
    "selected_features = anova_df_sorted[anova_df_sorted['p_value'] <= 0.05]\n",
    "\n",
    "# Imprimir las características seleccionadas\n",
    "print(\"Características seleccionadas (p-value <= 0.05):\")\n",
    "print(selected_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora separemos todo nuestro nuevo conjunto en train y test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(df.drop('y', axis=1), df.y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ya que separamos los datos generaremos 3 modelos SVM uno LINEAL, otro POLINOMIAL de tercer orden y uno RADIAL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluación del modelo SVM con kernel lineal:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00         4\n",
      "           2       1.00      1.00      1.00         4\n",
      "           3       1.00      1.00      1.00         3\n",
      "           4       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           1.00        17\n",
      "   macro avg       1.00      1.00      1.00        17\n",
      "weighted avg       1.00      1.00      1.00        17\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Crear y entrenar el modelo SVM con kernel lineal\n",
    "svm_linear = SVC(kernel='linear')\n",
    "svm_linear.fit(X_train, Y_train)\n",
    "\n",
    "\n",
    "# Crear y entrenar el modelo SVM con kernel polinomial de orden 3\n",
    "svm_poly = SVC(kernel='poly', degree=3)\n",
    "svm_poly.fit(X_train, Y_train)\n",
    "\n",
    "\n",
    "# Crear y entrenar el modelo SVM con kernel radial\n",
    "svm_rbf = SVC(kernel='rbf')\n",
    "svm_rbf.fit(X_train, Y_train)\n",
    "\n",
    "\n",
    "# Evaluar los modelos en el conjunto de prueba\n",
    "print(\"\\nEvaluación del modelo SVM con kernel lineal:\")\n",
    "print(classification_report(Y_test, svm_linear.predict(X_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluación del modelo SVM con kernel polinomial de orden 3:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00         4\n",
      "           2       1.00      1.00      1.00         4\n",
      "           3       1.00      1.00      1.00         3\n",
      "           4       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           1.00        17\n",
      "   macro avg       1.00      1.00      1.00        17\n",
      "weighted avg       1.00      1.00      1.00        17\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"\\nEvaluación del modelo SVM con kernel polinomial de orden 3:\")\n",
    "print(classification_report(Y_test, svm_poly.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluación del modelo SVM con kernel radial:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      0.75      0.86         4\n",
      "           2       0.80      1.00      0.89         4\n",
      "           3       1.00      1.00      1.00         3\n",
      "           4       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.94        17\n",
      "   macro avg       0.95      0.94      0.94        17\n",
      "weighted avg       0.95      0.94      0.94        17\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"\\nEvaluación del modelo SVM con kernel radial:\")\n",
    "print(classification_report(Y_test, svm_rbf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parece ser que nuestros modelos Lineal y Polinomial pueden predecir con un 100% de certesa cual de las 4 clases seria el nuevo valor, este solo reduciendose en el analisis Radial a un 94%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Métricas para el modelo SVM Lineal:\n",
      "Precisión: 1.0000\n",
      "Exactitud: 1.0000\n",
      "Sensibilidad (Recall): 1.0000\n",
      "Puntuación F1: 1.0000\n",
      "Matriz de confusión:\n",
      "[[4 0 0 0]\n",
      " [0 4 0 0]\n",
      " [0 0 3 0]\n",
      " [0 0 0 6]]\n",
      "\n",
      "\n",
      "Métricas para el modelo SVM Polinomial:\n",
      "Precisión: 1.0000\n",
      "Exactitud: 1.0000\n",
      "Sensibilidad (Recall): 1.0000\n",
      "Puntuación F1: 1.0000\n",
      "Matriz de confusión:\n",
      "[[4 0 0 0]\n",
      " [0 4 0 0]\n",
      " [0 0 3 0]\n",
      " [0 0 0 6]]\n",
      "\n",
      "\n",
      "Métricas para el modelo SVM Radial:\n",
      "Precisión: 0.9412\n",
      "Exactitud: 0.9529\n",
      "Sensibilidad (Recall): 0.9412\n",
      "Puntuación F1: 0.9402\n",
      "Matriz de confusión:\n",
      "[[3 1 0 0]\n",
      " [0 4 0 0]\n",
      " [0 0 3 0]\n",
      " [0 0 0 6]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "# Predicciones de los modelos\n",
    "y_pred_linear = svm_linear.predict(X_test)\n",
    "y_pred_poly = svm_poly.predict(X_test)\n",
    "y_pred_rbf = svm_rbf.predict(X_test)\n",
    "\n",
    "# Función para calcular métricas\n",
    "def calcular_metricas(y_true, y_pred, modelo):\n",
    "    print(f\"Métricas para el modelo {modelo}:\")\n",
    "    print(f\"Precisión: {accuracy_score(y_true, y_pred):.4f}\")\n",
    "    print(f\"Exactitud: {precision_score(y_true, y_pred, average='weighted'):.4f}\")\n",
    "    print(f\"Sensibilidad (Recall): {recall_score(y_true, y_pred, average='weighted'):.4f}\")\n",
    "    print(f\"Puntuación F1: {f1_score(y_true, y_pred, average='weighted'):.4f}\")\n",
    "    print(\"Matriz de confusión:\")\n",
    "    print(confusion_matrix(y_true, y_pred))\n",
    "    print(\"\\n\")\n",
    "\n",
    "# Calcular métricas para cada modelo\n",
    "calcular_metricas(Y_test, y_pred_linear, \"SVM Lineal\")\n",
    "calcular_metricas(Y_test, y_pred_poly, \"SVM Polinomial\")\n",
    "calcular_metricas(Y_test, y_pred_rbf, \"SVM Radial\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Presentado los modelos de una forma que sea mas facil de comparar podemos ver que el lineal y polinomial serian los mas adecuados para nuestro analisis ya que al parecer no parecen cometer errores."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
